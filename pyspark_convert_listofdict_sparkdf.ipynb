{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c537d0c-43d5-43b4-b142-9315b1602f1f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d41582e9-3a17-4d3e-af3a-671d0dd2b047",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master('local[1]').appName('pyspark_fresh').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8fb867b1-b493-4ab6-912a-5e2da06e7368",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_list = [{'user_id':1,'first_name':'dewil'},\n",
    "             {'user_id':2,'first_name':'williom'},\n",
    "             {'user_id':3,'first_name':'smith'},\n",
    "             {'user_id':4,'first_name':'maithew'}\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c03cda24-f9e2-483b-8988-198c84033185",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[first_name: string, user_id: bigint]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(user_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8ae7d95-7268-46c1-b933-19d69daa4f7a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-------+\n",
      "|first_name|user_id|\n",
      "+----------+-------+\n",
      "|     dewil|      1|\n",
      "|   williom|      2|\n",
      "|     smith|      3|\n",
      "|   maithew|      4|\n",
      "+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(user_list).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff9f138-5800-49e8-8479-74fe8c85242a",
   "metadata": {},
   "source": [
    "## It's depricated we need convert into Row then create df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7bab49a3-03d5-4121-9e79-1dadc99f36ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39d9d4f5-9aec-4169-b5c1-ac80475f30cd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_rows = [Row(*user.values()) for user in user_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd676ff1-67de-4a03-883b-850b969c9a17",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Row(1, 'dewil')>,\n",
       " <Row(2, 'williom')>,\n",
       " <Row(3, 'smith')>,\n",
       " <Row(4, 'maithew')>]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d706b0c-28ae-47f1-a5fe-458db4e7f1e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[_1: bigint, _2: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(user_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3a96956-df7d-4569-8884-a4a42320c686",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+\n",
      "| _1|     _2|\n",
      "+---+-------+\n",
      "|  1|  dewil|\n",
      "|  2|williom|\n",
      "|  3|  smith|\n",
      "|  4|maithew|\n",
      "+---+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(user_rows).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "270d7fb7-0198-4ed4-8581-af0bb39d41aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|user_id|first_name|\n",
      "+-------+----------+\n",
      "|      1|     dewil|\n",
      "|      2|   williom|\n",
      "|      3|     smith|\n",
      "|      4|   maithew|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(user_rows,schema='user_id int,first_name string').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "190f1def-d6f3-4bda-9421-95d58b564376",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_rows = [Row(**user) for user in user_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea77b99f-1d16-424b-8b4e-d6dff98f4351",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|user_id|first_name|\n",
      "+-------+----------+\n",
      "|      1|     dewil|\n",
      "|      2|   williom|\n",
      "|      3|     smith|\n",
      "|      4|   maithew|\n",
      "+-------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(user_rows,schema='user_id int,first_name string').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ac65a921-ad7a-4948-9d67-fbc061b135c4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def demo(*arg):\n",
    "    print(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed543f3f-7f5d-42c7-83b1-45e8d133fbb9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5,)\n"
     ]
    }
   ],
   "source": [
    "demo(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00515477-c5d1-4489-96ba-9852bc40cb98",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 6, 7)\n"
     ]
    }
   ],
   "source": [
    "demo(5,6,7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "27d60838-4a43-4feb-a0ba-4c81688fcc15",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([2, 4, 6, 8],)\n"
     ]
    }
   ],
   "source": [
    "demo([2,4,6,8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b8fc3511-7dbb-42a2-af20-196c718c8bfa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def demo(**arg):\n",
    "    print(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9918bdb6-efdf-411b-a192-454eb345ca87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "demo() takes 0 positional arguments but 1 was given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m demo(\u001b[38;5;241m5\u001b[39m)\n",
      "\u001b[1;31mTypeError\u001b[0m: demo() takes 0 positional arguments but 1 was given"
     ]
    }
   ],
   "source": [
    "demo(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "035a53d7-4a23-47ad-9cfe-1158b97d5416",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "demo(id=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "236cf4ed-0e2b-445a-a32d-8cba7a6a3be8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': [1, 2, 3, 4, 5, 6, 7, 9]}\n"
     ]
    }
   ],
   "source": [
    "demo(id=[1,2,3,4,5,6,7,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7fb0fd7c-f280-477c-88c0-333ac26b50d7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import datetime\n",
    "data = [ {\n",
    "        \"id\" : -1,\n",
    "        \"name\" : \"sid\",\n",
    "        \"dataTypeName\" : \"meta_data\",\n",
    "        \"fieldName\" : \":sid\",\n",
    "        \"position\" : 0,\n",
    "        \"renderTypeName\" : \"meta_data\",\n",
    "        \"format\" : '',\n",
    "        \"flags\" : \"hidden\",\n",
    "        \"date\" : datetime.date(2023,10,20),\n",
    "        \"timestamp\":datetime.datetime(2023,10,20, 10,36,45)\n",
    "      }, {\n",
    "        \"id\" : -1,\n",
    "        \"name\" : \"id\",\n",
    "        \"dataTypeName\" : \"meta_data\",\n",
    "        \"fieldName\" : \":id\",\n",
    "        \"position\" : 0,\n",
    "        \"renderTypeName\" : \"meta_data\",\n",
    "        \"format\" : 'json',\n",
    "        \"flags\" : \"hidden\",\n",
    "        \"date\" : datetime.date(2023,10,20),\n",
    "        \"timestamp\":datetime.datetime(2023,10,20, 10,36,45)\n",
    "      }, {\n",
    "        \"id\" : -1,\n",
    "        \"name\" : \"position\",\n",
    "        \"dataTypeName\" : \"meta_data\",\n",
    "        \"fieldName\" : \":position\",\n",
    "        \"position\" : 0,\n",
    "        \"renderTypeName\" : \"meta_data\",\n",
    "        \"format\" : 'json',\n",
    "        \"flags\" :  \"hidden\",\n",
    "        \"date\" : datetime.date(2023,10,20),\n",
    "        \"timestamp\":datetime.datetime(2023,10,20, 10,36,45)\n",
    "      }, {\n",
    "        \"id\" : -1,\n",
    "        \"name\" : \"created_at\",\n",
    "        \"dataTypeName\" : \"meta_data\",\n",
    "        \"fieldName\" : \":created_at\",\n",
    "        \"position\" : 0,\n",
    "        \"renderTypeName\" : \"meta_data\",\n",
    "        \"format\" : 'json',\n",
    "        \"flags\" :  \"hidden\",\n",
    "        \"date\" : datetime.date(2023,10,20),\n",
    "        \"timestamp\":datetime.datetime(2023,10,20, 10,36,45)\n",
    "      }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bfd5640d-cef9-4803-835a-37e425516ee1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "rows = [Row(**d) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7631c649-f9d1-4400-b02e-3c9190767e85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+-----------+--------+--------------+------+------+----------+-------------------+\n",
      "| id|      name|dataTypeName|  fieldName|position|renderTypeName|format| flags|      date|          timestamp|\n",
      "+---+----------+------------+-----------+--------+--------------+------+------+----------+-------------------+\n",
      "| -1|       sid|   meta_data|       :sid|       0|     meta_data|      |hidden|2023-10-20|2023-10-20 10:36:45|\n",
      "| -1|        id|   meta_data|        :id|       0|     meta_data|  json|hidden|2023-10-20|2023-10-20 10:36:45|\n",
      "| -1|  position|   meta_data|  :position|       0|     meta_data|  json|hidden|2023-10-20|2023-10-20 10:36:45|\n",
      "| -1|created_at|   meta_data|:created_at|       0|     meta_data|  json|hidden|2023-10-20|2023-10-20 10:36:45|\n",
      "+---+----------+------------+-----------+--------+--------------+------+------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(rows).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c5df041e-4a00-449c-bb2e-e7113d775f6d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = spark.createDataFrame(rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "41b19871-6788-4c2d-9cf4-0d647193921e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'bigint'),\n",
       " ('name', 'string'),\n",
       " ('dataTypeName', 'string'),\n",
       " ('fieldName', 'string'),\n",
       " ('position', 'bigint'),\n",
       " ('renderTypeName', 'string'),\n",
       " ('format', 'string'),\n",
       " ('flags', 'string'),\n",
       " ('date', 'date'),\n",
       " ('timestamp', 'timestamp')]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "67cda374-6cd6-43ab-b329-fcf191417638",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "schema = \"\"\"\n",
    "id INT,\n",
    "name STRING,\n",
    "dataTypeName STRING,\n",
    "fieldName STRING,\n",
    "position INT,\n",
    "renderTypeName STRING,\n",
    "format STRING,\n",
    "flags STRING,\n",
    "date DATE,\n",
    "timestamp TIMESTAMP\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "795e8850-5489-45e2-85b7-0eae9f3f9ae9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dff = spark.createDataFrame(rows,schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d40c9e49-4dd2-463f-acc8-258471cee81c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0caceec8-0d02-4e4a-8e7a-5ca4e0fd77bb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class StructType in module pyspark.sql.types:\n",
      "\n",
      "class StructType(DataType)\n",
      " |  StructType(fields: Optional[List[pyspark.sql.types.StructField]] = None)\n",
      " |  \n",
      " |  Struct type, consisting of a list of :class:`StructField`.\n",
      " |  \n",
      " |  This is the data type representing a :class:`Row`.\n",
      " |  \n",
      " |  Iterating a :class:`StructType` will iterate over its :class:`StructField`\\s.\n",
      " |  A contained :class:`StructField` can be accessed by its name or position.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from pyspark.sql.types import *\n",
      " |  >>> struct1 = StructType([StructField(\"f1\", StringType(), True)])\n",
      " |  >>> struct1[\"f1\"]\n",
      " |  StructField('f1', StringType(), True)\n",
      " |  >>> struct1[0]\n",
      " |  StructField('f1', StringType(), True)\n",
      " |  \n",
      " |  >>> struct1 = StructType([StructField(\"f1\", StringType(), True)])\n",
      " |  >>> struct2 = StructType([StructField(\"f1\", StringType(), True)])\n",
      " |  >>> struct1 == struct2\n",
      " |  True\n",
      " |  >>> struct1 = StructType([StructField(\"f1\", CharType(10), True)])\n",
      " |  >>> struct2 = StructType([StructField(\"f1\", CharType(10), True)])\n",
      " |  >>> struct1 == struct2\n",
      " |  True\n",
      " |  >>> struct1 = StructType([StructField(\"f1\", VarcharType(10), True)])\n",
      " |  >>> struct2 = StructType([StructField(\"f1\", VarcharType(10), True)])\n",
      " |  >>> struct1 == struct2\n",
      " |  True\n",
      " |  >>> struct1 = StructType([StructField(\"f1\", StringType(), True)])\n",
      " |  >>> struct2 = StructType([StructField(\"f1\", StringType(), True),\n",
      " |  ...     StructField(\"f2\", IntegerType(), False)])\n",
      " |  >>> struct1 == struct2\n",
      " |  False\n",
      " |  \n",
      " |  The below example demonstrates how to create a DataFrame based on a struct created\n",
      " |  using class:`StructType` and class:`StructField`:\n",
      " |  \n",
      " |  >>> data = [(\"Alice\", [\"Java\", \"Scala\"]), (\"Bob\", [\"Python\", \"Scala\"])]\n",
      " |  >>> schema = StructType([\n",
      " |  ...     StructField(\"name\", StringType()),\n",
      " |  ...     StructField(\"languagesSkills\", ArrayType(StringType())),\n",
      " |  ... ])\n",
      " |  >>> df = spark.createDataFrame(data=data, schema=schema)\n",
      " |  >>> df.printSchema()\n",
      " |  root\n",
      " |   |-- name: string (nullable = true)\n",
      " |   |-- languagesSkills: array (nullable = true)\n",
      " |   |    |-- element: string (containsNull = true)\n",
      " |  >>> df.show()\n",
      " |  +-----+---------------+\n",
      " |  | name|languagesSkills|\n",
      " |  +-----+---------------+\n",
      " |  |Alice|  [Java, Scala]|\n",
      " |  |  Bob|[Python, Scala]|\n",
      " |  +-----+---------------+\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      StructType\n",
      " |      DataType\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __getitem__(self, key: Union[str, int]) -> pyspark.sql.types.StructField\n",
      " |      Access fields by name or slice.\n",
      " |  \n",
      " |  __init__(self, fields: Optional[List[pyspark.sql.types.StructField]] = None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  __iter__(self) -> Iterator[pyspark.sql.types.StructField]\n",
      " |      Iterate the fields\n",
      " |  \n",
      " |  __len__(self) -> int\n",
      " |      Return the number of fields.\n",
      " |  \n",
      " |  __repr__(self) -> str\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  add(self, field: Union[str, pyspark.sql.types.StructField], data_type: Union[str, pyspark.sql.types.DataType, NoneType] = None, nullable: bool = True, metadata: Optional[Dict[str, Any]] = None) -> 'StructType'\n",
      " |      Construct a :class:`StructType` by adding new elements to it, to define the schema.\n",
      " |      The method accepts either:\n",
      " |      \n",
      " |          a) A single parameter which is a :class:`StructField` object.\n",
      " |          b) Between 2 and 4 parameters as (name, data_type, nullable (optional),\n",
      " |             metadata(optional). The data_type parameter may be either a String or a\n",
      " |             :class:`DataType` object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      field : str or :class:`StructField`\n",
      " |          Either the name of the field or a :class:`StructField` object\n",
      " |      data_type : :class:`DataType`, optional\n",
      " |          If present, the DataType of the :class:`StructField` to create\n",
      " |      nullable : bool, optional\n",
      " |          Whether the field to add should be nullable (default True)\n",
      " |      metadata : dict, optional\n",
      " |          Any additional metadata (default None)\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`StructType`\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from pyspark.sql.types import IntegerType, StringType, StructField, StructType\n",
      " |      >>> struct1 = StructType().add(\"f1\", StringType(), True).add(\"f2\", StringType(), True, None)\n",
      " |      >>> struct2 = StructType([StructField(\"f1\", StringType(), True),\n",
      " |      ...     StructField(\"f2\", StringType(), True, None)])\n",
      " |      >>> struct1 == struct2\n",
      " |      True\n",
      " |      >>> struct1 = StructType().add(StructField(\"f1\", StringType(), True))\n",
      " |      >>> struct2 = StructType([StructField(\"f1\", StringType(), True)])\n",
      " |      >>> struct1 == struct2\n",
      " |      True\n",
      " |      >>> struct1 = StructType().add(\"f1\", \"string\", True)\n",
      " |      >>> struct2 = StructType([StructField(\"f1\", StringType(), True)])\n",
      " |      >>> struct1 == struct2\n",
      " |      True\n",
      " |  \n",
      " |  fieldNames(self) -> List[str]\n",
      " |      Returns all field names in a list.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> from pyspark.sql.types import StringType, StructField, StructType\n",
      " |      >>> struct = StructType([StructField(\"f1\", StringType(), True)])\n",
      " |      >>> struct.fieldNames()\n",
      " |      ['f1']\n",
      " |  \n",
      " |  fromInternal(self, obj: Tuple) -> 'Row'\n",
      " |      Converts an internal SQL object into a native Python object.\n",
      " |  \n",
      " |  jsonValue(self) -> Dict[str, Any]\n",
      " |  \n",
      " |  needConversion(self) -> bool\n",
      " |      Does this type needs conversion between Python object and internal SQL object.\n",
      " |      \n",
      " |      This is used to avoid the unnecessary conversion for ArrayType/MapType/StructType.\n",
      " |  \n",
      " |  simpleString(self) -> str\n",
      " |  \n",
      " |  toInternal(self, obj: Tuple) -> Tuple\n",
      " |      Converts a Python object into an internal SQL object.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  fromJson(json: Dict[str, Any]) -> 'StructType' from builtins.type\n",
      " |      Constructs :class:`StructType` from a schema defined in JSON format.\n",
      " |      \n",
      " |      Below is a JSON schema it must adhere to::\n",
      " |      \n",
      " |          {\n",
      " |            \"title\":\"StructType\",\n",
      " |            \"description\":\"Schema of StructType in json format\",\n",
      " |            \"type\":\"object\",\n",
      " |            \"properties\":{\n",
      " |               \"fields\":{\n",
      " |                  \"description\":\"Array of struct fields\",\n",
      " |                  \"type\":\"array\",\n",
      " |                  \"items\":{\n",
      " |                      \"type\":\"object\",\n",
      " |                      \"properties\":{\n",
      " |                         \"name\":{\n",
      " |                            \"description\":\"Name of the field\",\n",
      " |                            \"type\":\"string\"\n",
      " |                         },\n",
      " |                         \"type\":{\n",
      " |                            \"description\": \"Type of the field. Can either be\n",
      " |                                            another nested StructType or primitive type\",\n",
      " |                            \"type\":\"object/string\"\n",
      " |                         },\n",
      " |                         \"nullable\":{\n",
      " |                            \"description\":\"If nulls are allowed\",\n",
      " |                            \"type\":\"boolean\"\n",
      " |                         },\n",
      " |                         \"metadata\":{\n",
      " |                            \"description\":\"Additional metadata to supply\",\n",
      " |                            \"type\":\"object\"\n",
      " |                         },\n",
      " |                         \"required\":[\n",
      " |                            \"name\",\n",
      " |                            \"type\",\n",
      " |                            \"nullable\",\n",
      " |                            \"metadata\"\n",
      " |                         ]\n",
      " |                      }\n",
      " |                 }\n",
      " |              }\n",
      " |           }\n",
      " |         }\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      json : dict or a dict-like object e.g. JSON object\n",
      " |          This \"dict\" must have \"fields\" key that returns an array of fields\n",
      " |          each of which must have specific keys (name, type, nullable, metadata).\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      :class:`StructType`\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> json_str = '''\n",
      " |      ...  {\n",
      " |      ...      \"fields\": [\n",
      " |      ...          {\n",
      " |      ...              \"metadata\": {},\n",
      " |      ...              \"name\": \"Person\",\n",
      " |      ...              \"nullable\": true,\n",
      " |      ...              \"type\": {\n",
      " |      ...                  \"fields\": [\n",
      " |      ...                      {\n",
      " |      ...                          \"metadata\": {},\n",
      " |      ...                          \"name\": \"name\",\n",
      " |      ...                          \"nullable\": false,\n",
      " |      ...                          \"type\": \"string\"\n",
      " |      ...                      },\n",
      " |      ...                      {\n",
      " |      ...                          \"metadata\": {},\n",
      " |      ...                          \"name\": \"surname\",\n",
      " |      ...                          \"nullable\": false,\n",
      " |      ...                          \"type\": \"string\"\n",
      " |      ...                      }\n",
      " |      ...                  ],\n",
      " |      ...                  \"type\": \"struct\"\n",
      " |      ...              }\n",
      " |      ...          }\n",
      " |      ...      ],\n",
      " |      ...      \"type\": \"struct\"\n",
      " |      ...  }\n",
      " |      ...  '''\n",
      " |      >>> import json\n",
      " |      >>> scheme = StructType.fromJson(json.loads(json_str))\n",
      " |      >>> scheme.simpleString()\n",
      " |      'struct<Person:struct<name:string,surname:string>>'\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from DataType:\n",
      " |  \n",
      " |  __eq__(self, other: Any) -> bool\n",
      " |      Return self==value.\n",
      " |  \n",
      " |  __hash__(self) -> int\n",
      " |      Return hash(self).\n",
      " |  \n",
      " |  __ne__(self, other: Any) -> bool\n",
      " |      Return self!=value.\n",
      " |  \n",
      " |  json(self) -> str\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from DataType:\n",
      " |  \n",
      " |  typeName() -> str from builtins.type\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from DataType:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(StructType)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "adc06518-b2bc-4c74-8cff-d611a04720d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4185418c-0f80-4f90-8d16-1c9a07486934",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "s_schema = StructType([StructField('id',IntegerType()),\n",
    "           StructField('name',StringType()),\n",
    "           StructField('dataTypeName',StringType()),\n",
    "           StructField('fieldName',StringType()),\n",
    "           StructField('position',IntegerType()),\n",
    "           StructField('renderTypeName',StringType()),\n",
    "           StructField('format',StringType()),\n",
    "           StructField('flags',StringType()),\n",
    "           StructField('date',DateType()),\n",
    "           StructField('timestamp',TimestampType())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "667e4510-eb72-4500-9c81-61bd4459a73f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+-----------+--------+--------------+------+------+----------+-------------------+\n",
      "| id|      name|dataTypeName|  fieldName|position|renderTypeName|format| flags|      date|          timestamp|\n",
      "+---+----------+------------+-----------+--------+--------------+------+------+----------+-------------------+\n",
      "| -1|       sid|   meta_data|       :sid|       0|     meta_data|      |hidden|2023-10-20|2023-10-20 10:36:45|\n",
      "| -1|        id|   meta_data|        :id|       0|     meta_data|  json|hidden|2023-10-20|2023-10-20 10:36:45|\n",
      "| -1|  position|   meta_data|  :position|       0|     meta_data|  json|hidden|2023-10-20|2023-10-20 10:36:45|\n",
      "| -1|created_at|   meta_data|:created_at|       0|     meta_data|  json|hidden|2023-10-20|2023-10-20 10:36:45|\n",
      "+---+----------+------------+-----------+--------+--------------+------+------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dff.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1314a3a1-65e2-4cc3-b640-19bd60305361",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+-----------+--------+--------------+------+------+----------+-------------------+\n",
      "| id|      name|dataTypeName|  fieldName|position|renderTypeName|format| flags|      date|          timestamp|\n",
      "+---+----------+------------+-----------+--------+--------------+------+------+----------+-------------------+\n",
      "| -1|       sid|   meta_data|       :sid|       0|     meta_data|      |hidden|2023-10-20|2023-10-20 10:36:45|\n",
      "| -1|        id|   meta_data|        :id|       0|     meta_data|  json|hidden|2023-10-20|2023-10-20 10:36:45|\n",
      "| -1|  position|   meta_data|  :position|       0|     meta_data|  json|hidden|2023-10-20|2023-10-20 10:36:45|\n",
      "| -1|created_at|   meta_data|:created_at|       0|     meta_data|  json|hidden|2023-10-20|2023-10-20 10:36:45|\n",
      "+---+----------+------------+-----------+--------+--------------+------+------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.createDataFrame(rows,schema=s_schema).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65bd93d2-848a-4628-bb45-006492b59ab9",
   "metadata": {},
   "source": [
    "## Create Spark Dataframe from pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c36b8386-13ce-4956-807e-9a42fc645a72",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': -1,\n",
       "  'name': 'sid',\n",
       "  'dataTypeName': 'meta_data',\n",
       "  'fieldName': ':sid',\n",
       "  'position': 0,\n",
       "  'renderTypeName': 'meta_data',\n",
       "  'format': '',\n",
       "  'flags': 'hidden',\n",
       "  'date': datetime.date(2023, 10, 20),\n",
       "  'timestamp': datetime.datetime(2023, 10, 20, 10, 36, 45)},\n",
       " {'id': -1,\n",
       "  'name': 'id',\n",
       "  'dataTypeName': 'meta_data',\n",
       "  'fieldName': ':id',\n",
       "  'position': 0,\n",
       "  'renderTypeName': 'meta_data',\n",
       "  'format': 'json',\n",
       "  'flags': 'hidden',\n",
       "  'date': datetime.date(2023, 10, 20),\n",
       "  'timestamp': datetime.datetime(2023, 10, 20, 10, 36, 45)},\n",
       " {'id': -1,\n",
       "  'name': 'position',\n",
       "  'dataTypeName': 'meta_data',\n",
       "  'fieldName': ':position',\n",
       "  'position': 0,\n",
       "  'renderTypeName': 'meta_data',\n",
       "  'format': 'json',\n",
       "  'flags': 'hidden',\n",
       "  'date': datetime.date(2023, 10, 20),\n",
       "  'timestamp': datetime.datetime(2023, 10, 20, 10, 36, 45)},\n",
       " {'id': -1,\n",
       "  'name': 'created_at',\n",
       "  'dataTypeName': 'meta_data',\n",
       "  'fieldName': ':created_at',\n",
       "  'position': 0,\n",
       "  'renderTypeName': 'meta_data',\n",
       "  'format': 'json',\n",
       "  'flags': 'hidden',\n",
       "  'date': datetime.date(2023, 10, 20),\n",
       "  'timestamp': datetime.datetime(2023, 10, 20, 10, 36, 45)}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "070ce5c2-9945-48ac-b820-7d7253a1a760",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+------------+-----------+--------+--------------+------+------+----------+-------------------+\n",
      "| id|      name|dataTypeName|  fieldName|position|renderTypeName|format| flags|      date|          timestamp|\n",
      "+---+----------+------------+-----------+--------+--------------+------+------+----------+-------------------+\n",
      "| -1|       sid|   meta_data|       :sid|       0|     meta_data|      |hidden|2023-10-20|2023-10-20 10:36:45|\n",
      "| -1|        id|   meta_data|        :id|       0|     meta_data|  json|hidden|2023-10-20|2023-10-20 10:36:45|\n",
      "| -1|  position|   meta_data|  :position|       0|     meta_data|  json|hidden|2023-10-20|2023-10-20 10:36:45|\n",
      "| -1|created_at|   meta_data|:created_at|       0|     meta_data|  json|hidden|2023-10-20|2023-10-20 10:36:45|\n",
      "+---+----------+------------+-----------+--------+--------------+------+------+----------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "spark.createDataFrame(pd.DataFrame(data=data)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a5c4e3-8f40-401a-b16a-c2b5b63037d9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
